{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Create_word_embedding",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davinhill/Convolution_Captioning/blob/master/embed/Create_word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P7oEpN54c_M",
        "colab_type": "code",
        "outputId": "e5eab85b-4761-45be-8347-f759e6ecc1cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7PNBFMtIog8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Path where the data should be located\n",
        "path = '/content/drive/My Drive/Colab Notebooks/IE534_ImageCaptioning/Data'\n",
        "os.chdir(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6LjW-OkIdlY",
        "colab_type": "code",
        "outputId": "03f4cf54-34bc-4ceb-95dc-e6851069f4f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from pycocotools.coco import COCO \n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import itertools\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDZw47qQ9yx5",
        "colab_type": "code",
        "outputId": "70a0d010-292d-43f6-9db1-b425d42657f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Load Captions from Annotation File\n",
        "\n",
        "##################\n",
        "# Validation Set\n",
        "##################\n",
        "# Load Annotations\n",
        "cap = COCO(os.path.join(path, 'annotations/captions_val2017.json'))\n",
        "\n",
        "# Create list of captions\n",
        "ann_ids = cap.getAnnIds(imgIds = [])\n",
        "ann_list = cap.loadAnns(ids = ann_ids)\n",
        "\n",
        "cap_val_raw = []\n",
        "for dict in ann_list:\n",
        "  cap_val_raw.append(dict['caption'])\n",
        "\n",
        "##################\n",
        "# Train Set\n",
        "##################\n",
        "# Load Annotations\n",
        "cap = COCO(os.path.join(path, 'annotations/captions_train2017.json'))\n",
        "\n",
        "# Create list of captions\n",
        "ann_ids = cap.getAnnIds(imgIds = [])\n",
        "ann_list = cap.loadAnns(ids = ann_ids)\n",
        "\n",
        "cap_train_raw = []\n",
        "for dict in ann_list:\n",
        "  cap_train_raw.append(dict['caption'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.83s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=3.09s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sqlziIH_XLE",
        "colab_type": "code",
        "outputId": "c0e5015c-1258-44a8-f4e0-85c4c2a017b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Number of Captions:\n",
        "len(cap_train_raw)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "591753"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAAgqRcKKALn",
        "colab_type": "code",
        "outputId": "c26c4aa7-ef6f-4668-abd4-a45ecd817f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tokenize Caption List\n",
        "\n",
        "cap_val = []\n",
        "for caption in cap_val_raw:\n",
        "  line = nltk.word_tokenize(caption)\n",
        "  line = [w.lower() for w in line] \n",
        "  cap_val.append(line)\n",
        "\n",
        "\n",
        "cap_train = []\n",
        "for caption in cap_train_raw:\n",
        "  line = nltk.word_tokenize(caption)\n",
        "  line = [w.lower() for w in line] \n",
        "  cap_train.append(line)\n",
        "\n",
        "\n",
        "# summarize token statistics\n",
        "x = []\n",
        "for tokens in cap_train:\n",
        "    x.append(len(tokens))\n",
        "x = np.asarray(x)\n",
        "print('Total: ', np.sum(x), ' Min: ', np.min(x), ' Max: ', np.max(x), ' Mean: ', np.mean(x), ' Std: ', np.std(x), ' Med: ', np.median(x))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total:  6687792  Min:  6  Max:  57  Mean:  11.301661335050266  Std:  2.596305429474608  Med:  11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rycAXy5X_tpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create word_to_id and id_to_word translations\n",
        "# word_to_id is a dictionary\n",
        "# id_to_word is a np array\n",
        "\n",
        "all_tokens = itertools.chain.from_iterable(cap_train)\n",
        "word_to_id = {token: idx for idx, token in enumerate(set(all_tokens))}\n",
        "\n",
        "\n",
        "all_tokens = itertools.chain.from_iterable(cap_train)\n",
        "id_to_word = np.asarray([token for idx, token in enumerate(set(all_tokens))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgI8rBpZBDl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## sort by word frequency\n",
        "\n",
        "token_ids = [[word_to_id[token] for token in x] for x in cap_train]\n",
        "count = np.zeros(id_to_word.shape)\n",
        "\n",
        "for x in token_ids:\n",
        "    for token in x:\n",
        "        count[token] += 1\n",
        "        \n",
        "indices = np.argsort(-count)\n",
        "id_to_word = id_to_word[indices]\n",
        "count = count[indices]\n",
        "\n",
        "\n",
        "## recreate word_to_id based on sorted list\n",
        "word_to_id = {token: (idx+4) for idx, token in enumerate(id_to_word)}\n",
        "\n",
        "# add start/end/unknown token\n",
        "word_to_id['<S>'] = 1\n",
        "word_to_id['</S>'] = 2\n",
        "word_to_id['UNK'] = 3\n",
        "\n",
        "# add start/end/unknown token\n",
        "id_to_word = np.insert(id_to_word, 0, 'UNK')\n",
        "id_to_word = np.insert(id_to_word, 0, '</S>')\n",
        "id_to_word = np.insert(id_to_word, 0, '<S>')\n",
        "id_to_word = np.insert(id_to_word, 0, '<MASK>')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrW07PCUAh52",
        "colab_type": "code",
        "outputId": "1b2c69a8-4533-4d63-e4aa-9e419ad17273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test\n",
        "\n",
        "id_to_word[word_to_id.get('dog')]\n",
        "\n",
        "id_to_word[18]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "','"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa0ZFkVMNZrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save to file\n",
        "\n",
        "\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/IE534_ImageCaptioning/')\n",
        "\n",
        "# save word_to_id\n",
        "import pickle\n",
        "with open('word_to_id.p', 'wb') as fp:\n",
        "    pickle.dump(word_to_id, fp, protocol=4)\n",
        "\n",
        "## save id_to_word\n",
        "np.save('id_to_word.npy',np.asarray(id_to_word))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}