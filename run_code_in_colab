{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run_code_in_colab","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"7P7oEpN54c_M","colab_type":"code","outputId":"a762b05f-9184-4b90-826c-96971b9b040f","executionInfo":{"status":"ok","timestamp":1574474623897,"user_tz":360,"elapsed":20937,"user":{"displayName":"Davin Hill","photoUrl":"","userId":"04463690813500185173"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IFX_zLok9WMx","colab_type":"code","colab":{}},"source":["import os\n","\n","# Path where the code is located\n","path = '/content/drive/My Drive/Colab Notebooks/IE534_ImageCaptioning'\n","os.chdir(path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i6LjW-OkIdlY","colab_type":"code","outputId":"bfd41b5e-c04e-4661-b969-83aeec0cd560","executionInfo":{"status":"ok","timestamp":1574474855554,"user_tz":360,"elapsed":252577,"user":{"displayName":"Davin Hill","photoUrl":"","userId":"04463690813500185173"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","!python train.py  \\\n","    --data_path '/content/drive/My Drive/Colab Notebooks/IE534_ImageCaptioning/Data'   \\\n","    --batch_size 2\n","    \n","    \n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","loading annotations into memory...\n","Done (t=3.26s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.52s)\n","creating index...\n","index created!\n","> /content/drive/My Drive/Colab Notebooks/IE534_ImageCaptioning/train.py(47)<module>()\n","-> model_vgg = vgg_extraction()\n","(Pdb) ll\n","  1  \timport torch\n","  2  \tfrom torchvision import models\n","  3  \timport torch.nn as nn\n","  4  \timport numpy as np\n","  5  \t\n","  6  \timport argparse\n","  7  \timport os\n","  8  \tfrom datetime import datetime\n","  9  \t\n"," 10  \tfrom models import conv_captioning, vgg_extraction\n"," 11  \tfrom dataloader import load_data, id_to_word\n"," 12  \t\n"," 13  \t# ======================================================\n"," 14  \t    # Input Parameters\n"," 15  \t# ======================================================\n"," 16  \t\n"," 17  \tparser = argparse.ArgumentParser()\n"," 18  \t\n"," 19  \tparser.add_argument('--data_path', type=str, default=os.path.dirname(os.path.realpath(__file__)), help='path where data & annotations are located')\n"," 20  \tparser.add_argument('--num_epochs', type=int, default=30)\n"," 21  \tparser.add_argument('--vocab_size', type=int, default=10000)\n"," 22  \tparser.add_argument('--max_cap_len', type=int, default=15, help = 'maximum caption length')\n"," 23  \tparser.add_argument('--batch_size', type=int, default=128)\n"," 24  \tparser.add_argument('--initial_lr', type=int, default=5 * np.exp(-5))\n"," 25  \tparser.add_argument('--scheduler_gamma', type=int, default=0.1)\n"," 26  \tparser.add_argument('--scheduler_stepsize', type=int, default=15)\n"," 27  \t\n"," 28  \targs = parser.parse_args()\n"," 29  \t\n"," 30  \t# ======================================================\n"," 31  \t    # Initialize Model\n"," 32  \t# ======================================================\n"," 33  \t\n"," 34  \tdevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"," 35  \t\n"," 36  \ttrainloader, valloader = load_data(path = args.data_path, batch_size = args.batch_size, vocab_size = args.vocab_size, max_cap_len=args.max_cap_len)\n"," 37  \t\n"," 38  \titerator = iter(valloader)\n"," 39  \t\n"," 40  \timage, caption, caption_tknID, word_mask = next(iterator)\n"," 41  \t\n"," 42  \t# Check that the tokenized caption is correct:\n"," 43  \tid_to_word_array = np.load('id_to_word.npy')\n"," 44  \ta = id_to_word(caption_tknID, id_to_word_array)\n"," 45  \t\n"," 46  \timport pdb; pdb.set_trace()\n"," 47  ->\tmodel_vgg = vgg_extraction()\n"," 48  \tmodel_vgg.to(device)\n"," 49  \t\n"," 50  \tmodel_cc = conv_captioning()\n"," 51  \tmodel_cc.to(device)\n"," 52  \t\n"," 53  \t\n"," 54  \t\n"," 55  \t# Initialize optimizer\n"," 56  \toptimizer = torch.optim.RMSProp(model_cc.parameters(), lr = args.initial_lr)\n"," 57  \tscheduler = torch.optim.lr_scheduler.StepLR(optimizer, gamma = args.scheduler_gamma, step_size = args.scheduler_stepsize )\n"," 58  \t\n"," 59  \t# Criterion\n"," 60  \tcriterion = nn.CrossEntropyLoss()\n"," 61  \t\n"," 62  \t\n"," 63  \t\n"," 64  \t# ======================================================\n"," 65  \t    # Train\n"," 66  \t# ======================================================\n"," 67  \t\n","(Pdb) caption\n","[('A girl taking a swing at a baseball during a game.', 'A close up of a bike brake on a bicycle.')]\n","(Pdb) caption_tknID\n","tensor([[   1,    4,   97,  230,    4,  449,   19,    4,   55,  256,    4,   95,\n","            5,    2,    0,    0,    0,    0],\n","        [   1,    4,  142,   37,    7,    4,  233, 5225,    6,    4,  357,    5,\n","            2,    0,    0,    0,    0,    0]])\n","(Pdb) caption_tknID.shape\n","torch.Size([2, 18])\n","(Pdb) image.shape\n","torch.Size([2, 3, 224, 224])\n","(Pdb) q\n","Traceback (most recent call last):\n","  File \"train.py\", line 47, in <module>\n","    model_vgg = vgg_extraction()\n","  File \"train.py\", line 47, in <module>\n","    model_vgg = vgg_extraction()\n","  File \"/usr/lib/python3.6/bdb.py\", line 51, in trace_dispatch\n","    return self.dispatch_line(frame)\n","  File \"/usr/lib/python3.6/bdb.py\", line 70, in dispatch_line\n","    if self.quitting: raise BdbQuit\n","bdb.BdbQuit\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wr48mIM6DR99","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}